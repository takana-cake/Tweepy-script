'''

---------------
Description
---------------
file_path/
　├ vtubermedia_downloader.py
　├ user_list.json
　├ tag_list.txt
　├ user1/
　│　└ <dl media>
　├ user2/

1. ユーザごとにハッシュタグを保持。とりあえずjsonで管理
	vtuber{user1:{TL用:date, tag1:date, tag2:date}, user2:{TL用:date, tag1:date, tag2:date}}
2. プロフィールとTLのハッシュタグを監視
	user_description_check()　プロフ
	TL検索時についでにチェック
3. ハッシュタグの関連付け(追加)は手動
	hashtag_add()　引数あり(ユーザ、タグ1、タグ2・・・)
4. ハッシュタグで検索。最終検索時刻保持
	search_hashtags()
5. ユーザのTLを検索。最終検索時刻保持
	search_user_tl()

とりあえずダブり画像は考えないものとする

---------------
Flow
---------------
init jsonチェック
user or hash追加チェック
ユーザプロフチェック
TLチェック
ハッシュタグチェック

'''

# _*_ coding: utf-8 _*_

import tweepy
import sys
import urllib.request
import os
import datetime
import time
import json



def tweepy_api():
	twitter_conf = {
	    'consumer' : {
	        'key'    : "",
	        'secret' : ""
	    },
	    'access'   : {
	        'key'    : "",
	        'secret' : ""
	    }
	}
	auth = tweepy.OAuthHandler(
	    twitter_conf['consumer']['key'],
	    twitter_conf['consumer']['secret'])
	auth.set_access_token(
	    twitter_conf['access']['key'],
	    twitter_conf['access']['secret'])
	tweepy_auth = tweepy.API(auth)
	return(tweepy_auth)

def init_script():
	print('please run "python3 vtubermedia_downloader.py user_add user1 user2..."')
	sys.exit()

def user_add(users):
	del users[0:2]
	for i in users:
		if hasattr(user_list_json, i) is False:
			user_dict = {k:"" for k in user_description_check(i)}
			user_dict.update({"dummy",""})
			user_list_add[i] = user_dict
	return(user_list_useradd)

def hashtag_add(tags):
	key = tags[2]
	del tags[0:3]
	return(user_list_tagadd)

def user_description_check(check_userid):
	description = api.get_user(check_userid).description
	description = re.sub(r'#', " #", description)
	pattern = re.compile(r'[\s\[\]\(\)\<\>\（\）\＜\＞\"\']')
	description_split = re.split(pattern, description)
	description_hashtags = [x for x in description_split if '#' in x]
	return(description_hashtags)

def search_hashtags(s_hashtags):
	# since = 2016-08-26_00:00:00_JST
	# until = 2016-08-26_23:59:59_JST
	retry_count = 0
	for hashtag,date in s_hashtags.items():
		if date:
			search_query = 'since_search'
		else:
			search_query = 'until_search'
			date = datetime.datetime.today().strftime("%Y-%m-%d_%H:%M:%S_JST")
		for l in range(50):
			try:
				if search_query == 'since_search':
					for twi in api.search(q=hashtag, count=100, since=date):
						date = datetime.datetime.today().strftime("%Y-%m-%d_%H:%M:%S_JST")
						media_get(twi)
				else:
					for twi in api.search(q=hashtag, count=100, until=date):
						date = datetime.datetime.today().strftime("%Y-%m-%d_%H:%M:%S_JST")
						media_get(twi)
			except tweepy.RateLimitError as err:
				retry_count = retry_count +1
				if retry_count < 3:
					time.sleep(60 * 5)
					continue
				else:
					retry_count = 0
			except:
				retry_count = retry_count +1
				if retry_count < 3:
					time.sleep(10)
					continue
				else:
					retry_count = 0
			retry_count = 0
		hashtag_json[hash_tag] = tweet_id
	f = open(working_directory + "/_hashtag_list.json",'w')
	json.dump(hashtag_json,f)
	f.close()

def search_user_tl(s_user,s_date):
	for twi in api.search(q="#testing", count=10, until=s_date, tweet_mode = 'extended'):
		print(twi.full_text)

def media_get(twi_def):
	mediaget_fault_count = 0
		if hasattr(twi_def, "extended_entities"):
			if 'media' in twi_def.extended_entities:
				for media in twi_def.extended_entities["media"]:
					if media["type"] == 'photo':
						dl_filename = media["media_url"]
						dl_media = dl_filename + ":orig"
					if media["type"] == 'animated_gif':
						dl_media = media["video_info"]["variants"][0]["url"]
						dl_filename = dl_media
					if media["type"] == 'video':
						dl_media = media["video_info"]["variants"][0]["url"]
						if '.m3u8' in dl_media:
							dl_media = media["video_info"]["variants"][1]["url"]
						if '?tag=' in dl_media:
							dl_media = dl_media[:-6]
						dl_filename = dl_media
					if os.path.exists(working_directory + "/" + os.path.basename(dl_filename)) == False:
						try:
							with open(working_directory + "/" + os.path.basename(dl_filename), 'wb') as f:
								dl_file = urllib.request.urlopen(dl_media).read()
								f.write(dl_file)
						except tweepy.RateLimitError as err:
							mediaget_fault_count = mediaget_fault_count +1
							if mediaget_fault_count < 3:
								time.sleep(60 * 5)
								continue
							else:
								mediaget_fault_count = 0
						except Exception as err:
							mediaget_fault_count = mediaget_fault_count +1
							if mediaget_fault_count < 3:
								time.sleep(60)
								continue
							else:
								mediaget_fault_count = 0
					mediaget_fault_count = 0



# main

file_path = os.getcwd()
if os.path.exists(file_path + "/user_list.json") == True:
	json_file = open(file_path + "/user_list.json",'r')
	user_list_json = json.load(json_file)
	json_file.close()

args = sys.argv
if len(args) != 1:
	if args[1] is 'user_add':
		user_list_new = user_add(args)
	elif os.path.exists(file_path + "/user_list.json") == False:
		init_script()
	elif args[1] is 'hashtag_add':
		user_list_new = hashtag_add(args)
	else:
		print("please chech again: " + args)
		sys.exit()
elif os.path.exists(file_path + "/user_list.json") == False:
	init_script()

json_file = open(file_path + "/user_list.json",'w')
json.dump(user_list_new,json_file)
json_file.close()

api = tweepy_api()
for user,tags in user_list_new.items():
	for i in user_description_check(user):
		if i not in tags:
			tags.update({i, ""})
	search_user_tl(user,tags["dummy"])
	search_hashtags(tags)
	user_list_new[user] = tags

json_file = open(file_path + "/user_list.json",'w')
json.dump(user_list_new,json_file)
json_file.close()
